#from pip._internal import main as pip
#pip(['install', '--user', 'netCDF4'])
"""
Dieses Skript dient zur jährlichen Aktualisierung der txt-Files
Folgende Dinge sind zu tun;
    - Pfade anpassen
    - Importjahr anpassen
"""

# Anpassungen 04.10.2023: Aktualisierung auf Spartacus2


print("Packages importieren...")
import netCDF4 as nc
from scipy import stats
import numpy as np
import pandas as pd
import os
import datetime

import csv

print("Packages importiert!")

# todo: Batch File

path_to_netcd_files = r"..."
path_to_txt_files = r"...\txt_files\day"  # Pfad zu Tages-Txt-Files
path_to_txt_files_month = r"...\txt_files\month"  # Pfad zu Monats-Txt-Files

importjahr = 2023  # Welches Jahr wird importiert?

# Folgender Abschnitt holt nur Koordinaten raus, damit später Koordinaten mit cell_ids verbunden werden kann  => einmalige Geschichte
fn = path_to_netcd_files+"SPARTACUS2-DAILY_RR_"+str(importjahr)+".nc"
ds = nc.Dataset(fn)

print("-------------------------")

prcp = ds["RR"][:]  # Niederschlagswerte
lat = ds["lat"][:]  # Latitude
lon = ds["lon"][:]  # Longitude
time = ds["time"][:]    # Zeit

# Get Statistics of MaskedArrays
print("prcp Masked Array Shape: "+str(prcp.shape))
print("lat Masked Array Shape: "+str(lat.shape))
print("lon Masked Array Shape: "+str(lon.shape))
print("Time Masked Array Shape: "+str(time.shape))

#merged_array = np.ma.array(str(lat)+","+str(lon), mask=lat.mask)
#print(merged_array)


## Algemeiner Teil: Zuweisung X und Y für jede Zelle; schauen was in der Steiermark liegt (im Buffer von 500 Meter);
raw_latlist = []
raw_lonlist = []
raw_rrlist = []

for val in lat.compressed():    # Latitudes werden rausgeholt und an Liste angehängt
    raw_latlist.append(val)

for val in lon.compressed():
    raw_lonlist.append(val)

for val in prcp.compressed():
    raw_rrlist.append(val)

print("Länge von raw_latlist: "+str(len(raw_latlist)))
print("Länge von raw_lonlist: "+str(len(raw_lonlist)))

print("Statistics von raw_latlist: ")
print(stats.describe(raw_latlist))

print("Statistics von raw_lonlist: ")
print(stats.describe(raw_lonlist))

latlon_df = pd.DataFrame({'lat': raw_latlist, 'lon': raw_lonlist})  # Dataframe wird erstellt; cell_id wird definiert
latlon_df['cell_id'] = range(1, len(latlon_df) + 1)

print(latlon_df)



def CreatePoint():
    import arcpy
    output_path = r"...\preprocessing"
    output_name = "coords_from_netcdf.shp"
    output_name_buffer = "bezirksgrenzen_buffer"
    sr = arcpy.SpatialReference(4326)
    arcpy.Delete_management(output_path+"\\"+output_name)
    arcpy.CreateFeatureclass_management(out_path=output_path, out_name=output_name, geometry_type="POINT", spatial_reference=sr)
    arcpy.AddField_management(output_path+"\\"+output_name, "cell_id", "LONG")

    cursor = arcpy.da.InsertCursor(os.path.join(output_path, output_name), ["cell_id", "SHAPE@X", "SHAPE@Y"])
    for row in zip(latlon_df["cell_id"],latlon_df["lon"], latlon_df["lat"]):
        cursor.insertRow((row[0], row[1], row[2]))
    del cursor

    sde_vector = r"...\Vectordaten.sde"
    bezirksgrenzen = arcpy.MakeFeatureLayer_management(f'{sde_vector}\\bez', "bezirksgrenzen")
    arcpy.MakeFeatureLayer_management(output_path+"\\"+output_name, "cells")
    arcpy.SelectLayerByLocation_management("cells", "INTERSECT", "bezirksgrenzen", "1000 Meters", "NEW_SELECTION")

    listofselectedcellids = []

    for row in arcpy.da.SearchCursor("cells", ["cell_id"]): #will only search through selected records (or all records if none are selected)
        listofselectedcellids.append(str(row[0]))

    with open(output_path+"\\selected_cellids.txt", "w", encoding="UTF8") as f:
        f.write(";".join(listofselectedcellids))

# CreatePoint()  # diente nur zur Koordinatenermittlung - was liegt in der STMK?

result = np.full((329, 584), "000000000000000000000000000000000000000000")  # die vielen 0er haben das Ziel, dass keine Werte abgeschnitten werden (ist passiert bei '000')

df_cellids_position = pd.DataFrame()

lst_cell_id = []
lst_lat = []
lst_lon = []
lst_i = []
lst_j = []

counter = 0
for i in range(len(lat)):   # durch alle Zellwerte gehen (x und y) und jedem Punkt eine cell_id zuweisen
    for j in range(len(lat[0])):
        counter = counter + 1
        result[i][j] = str(counter)+","+str(lat[i][j])+","+str(lon[i][j])
        lst_cell_id.append(str(counter))
        lst_lat.append(str(lat[i][j]))
        lst_lon.append(str(lon[i][j]))
        lst_i.append(i)
        lst_j.append(j)

df_cellids_position["cell_id"] = lst_cell_id        # Dataframe mit allen wichtigen Infos zusammengefasst; so bekommt man richtige x,y-Werte für jede cell_id aus der netcdf-Datei
df_cellids_position["lat"] = lst_lat
df_cellids_position["lon"] = lst_lon
df_cellids_position["i"] = lst_i
df_cellids_position["j"] = lst_j

cell_ids_styria_list = []
cell_ids_styria_list_already_calced = []


def get_files(path):    # Checkt, welche Files in Pfad vorhanden sind
    for file in os.listdir(path):
        if os.path.isfile(os.path.join(path, file)):
            yield file


for file in get_files(path_to_txt_files):  # extrahiert die IDs aller Dateien
    data_length = len(file)
    if data_length >= 14:
        id = file[4:10]
    else:
        id = file[4:9]
    cell_ids_styria_list.append(id)

print(cell_ids_styria_list)
print(len(cell_ids_styria_list))



# For-Loop über cell_ids_styrialist # cell_id 1
def Getdata():
    for cell in cell_ids_styria_list:
        print(cell)
        # get i und j
        idx = int(cell)-1
        i_iter = df_cellids_position.iloc[idx]["i"]
        print(i_iter)
        j_iter = df_cellids_position.iloc[idx]["j"]
        print(j_iter)
        # for loop über Jahre
        df_output = pd.DataFrame()
        d_output = []
        df_output_month = pd.DataFrame()
        d_output_month = []
        for year in range(importjahr, importjahr+1):       # for-Schleife eigentlich nicht mehr notwendig, wird aber gelassen
            #### DAILY STATS ######################
            # RR
            fn_rr = path_to_netcd_files+'\\SPARTACUS2-DAILY_RR_'+str(year)+'.nc'     # Tagesniederschlag rausholen
            ds_rr = nc.Dataset(fn_rr)
            prcp_rr = ds_rr["RR"][:]
            time = ds_rr["time"][:]

            # Testabfrage ob überhaupt Werte drinnen sind
            if str(prcp_rr[0, i_iter, j_iter]) == "--":     # wenn kein Wert vorhanden (=> außerhalb des Untersuchungsraumes der ZAMG)
                print("Keine Werte vorhanden - Cell wird übersprungen!")
                break

            # Tx
            fn_tx = path_to_netcd_files+'\\SPARTACUS2-DAILY_TX_' + str(year) + '.nc'     # Tagesmaximaltemp. rausholen
            ds_tx = nc.Dataset(fn_tx)
            prcp_tx = ds_tx["TX"][:]
            # Tn
            fn_tn = path_to_netcd_files+'\\SPARTACUS2-DAILY_TN_' + str(year) + '.nc'     # Tagesminimaltemp. rausholen
            ds_tn = nc.Dataset(fn_tn)
            prcp_tn = ds_tn["TN"][:]
            for day in range(0, prcp_rr.shape[0]):      # durch alle Tage durchgehen pro Jahr und Ergebnisse aufbereiten
                datum = datetime.datetime(year, 1, 1) + datetime.timedelta(day)     # Datum richtig formatieren; datatime.timedelta => in welchem Tag des Jahres befinden wir uns?
                val_rr = prcp_rr[day, i_iter, j_iter]   # richtigen rr-Wert rausholen => je nach x und y Wert
                print("Time: " + str(datum))
                print("cell: " + str(cell)+"; Jahr: " + str(year) + "; i: "+str(i_iter) + "; j: "+str(j_iter) + "; Tag: " + str(day+1)+"; RR: " + str(val_rr))
                val_tx = prcp_tx[day, i_iter, j_iter]
                print("cell: " + str(cell) + "; Jahr: " + str(year) + "; i: " + str(i_iter) + "; j: " + str(j_iter) + "; Tag: " + str(day + 1) + "; Tx: " + str(val_tx))
                val_tn = prcp_tn[day, i_iter, j_iter]
                print("cell: " + str(cell) + "; Jahr: " + str(year) + "; i: " + str(i_iter) + "; j: " + str(j_iter) + "; Tag: " + str(day + 1) + "; Tn: " + str(val_tn))
                try:
                    val_rr = round(val_rr, 1)
                    val_tx = round(val_tx, 1)
                    val_tn = round(val_tn, 1)
                except:
                    pass
                d_output.append(        # Ergebnis einem Dictionary hinzufügen => damit später ein Dataframe kreeiert werden kann
                    {
                        'timestamp': str(datum),
                        'RR': str(round(float(val_rr),1)),
                        'Tx': str(round(float(val_tx),1)),
                        'Tn': str(round(float(val_tn),1))
                    }
                )
            ################################

            #### MONTHLY STATS #############

            # RR
            fn_rr_month = path_to_netcd_files+'\\SPARTACUS2-MONTHLY_RR_' + str(year) + '.nc'     # Monatswerte für jedes jahr rausholen => Hier Niederschlag
            ds_rr_month = nc.Dataset(fn_rr_month)
            prcp_rr_month = ds_rr_month["RR"][:]
            time_month = ds_rr_month["time"][:]
            # Tm
            fn_tx_month = path_to_netcd_files+'\\SPARTACUS2-MONTHLY_TM_' + str(year) + '.nc'     # => Hier Durchschnittstemperatur
            ds_tx_month = nc.Dataset(fn_tx_month)
            prcp_tx_month = ds_tx_month["TM"][:]

            for month in range(0, prcp_rr_month.shape[0]):      # Durch alle Monate durchgehen

                if str(prcp_rr_month[0, i_iter, j_iter]) == "--":       # wenn außerhalb des Untersuchungsraumes der ZAMG; dann überspringen
                    print("Keine Werte vorhanden - Cell wird übersprungen!")
                    break

                print("-------- MONTH --------")
                datum_month = datetime.datetime(year, month+1, 1)
                val_rr_month = prcp_rr_month[month, i_iter, j_iter]
                print("Time_Month: " + str(datum_month))
                print("cell: " + str(cell) + "; Jahr: " + str(year) + "; i: " + str(i_iter) + "; j: " + str(
                    j_iter) + "; Monat: " + str(month + 1) + "; RR: " + str(val_rr_month))
                val_tm_month = prcp_tx_month[month, i_iter, j_iter]
                print("cell: " + str(cell) + "; Jahr: " + str(year) + "; i: " + str(i_iter) + "; j: " + str(
                    j_iter) + "; Monat: " + str(month + 1) + "; Tm: " + str(val_tm_month))
                try:
                    val_rr_month = round(val_rr_month, 1)
                    val_tm_month = round(val_tm_month, 1)
                except:
                    pass
                d_output_month.append(
                    {
                        'timestamp': str(datum_month),
                        'RR': str(round(float(val_rr_month),1)),
                        'Tm': str(round(float(val_tm_month),1)),
                    }
                )
                ################################

        modus = "Aktualisieren"
        #if modus == "Neu berechnen":
        #    df_output = pd.DataFrame(d_output)
        #    np.savetxt(r"C:\Users\kammer17\Desktop\KLIWA-Tool\preprocessing\txt_files\day\day_"+str(cell)+".txt", df_output.values, fmt="%s", delimiter=";")
        #    df_output_month = pd.DataFrame(d_output_month)
        #    np.savetxt(r"C:\Users\kammer17\Desktop\KLIWA-Tool\preprocessing\txt_files\month\month_" + str(cell) + ".txt",
        #               df_output_month.values, fmt="%s", delimiter=";")
        if modus == "Aktualisieren":    # hier werden Werte nur hinten angefügt und keine neue Datei erstellt (wie oben)
            df_output = pd.DataFrame(d_output)
            df_output_month = pd.DataFrame(d_output_month)
            with open(path_to_txt_files+"\\day_"+str(cell)+".txt", "ab") as f:
                np.savetxt(f, df_output.values, fmt="%s", delimiter=";")

            with open(path_to_txt_files_month+"\\month_"+str(cell)+".txt", "ab") as f:
                np.savetxt(f, df_output_month.values, fmt="%s", delimiter=";")

        ######################################


Getdata()


